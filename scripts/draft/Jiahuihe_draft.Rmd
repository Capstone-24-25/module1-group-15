---
title: "module1"
output: html_document
date: "2024-10-29"
---

```{r}
# Set the file path (if necessary)
file_path <- "/Users/emmahe/Documents/GitHub/Module0-t_team9/module1-group-15/data/biomarker-raw.csv"

# Read the CSV file into a dataframe
biomarker_data <- read.csv(file_path)

# Display the top 6 column names of biomarker_data
head(biomarker_data)
```

# Q3. 
```{r}
load("~/Documents/GitHub/Module0-t_team9/module1-group-15/data/biomarker-clean.RData")

# Check the names of objects loaded into the environment
ls()

# Display the first few rows of the loaded data (assuming the data frame is named biomarker_clean)
head(biomarker_clean)
```
```{r}
# Load necessary libraries
library(caret) # For data splitting

# Set a random seed for reproducibility
set.seed(101422)

# Split data: 80% training, 20% testing
trainIndex <- createDataPartition(biomarker_clean$group, p = 0.8, list = FALSE)
training_data <- biomarker_clean[trainIndex, ]
testing_data <- biomarker_clean[-trainIndex, ]

# Check data splits
dim(training_data) # Should be about 80% of data
dim(testing_data)  # Should be about 20% of data

head(training_data)
head(testing_data)
```

```{r}
# Load necessary libraries
library(randomForest)  # For random forest
library(glmnet)        # For lasso regression
library(caret)         # For data imputation and pre-processing
library(dplyr)         # For data manipulation

# Define the number of top proteins to select
num_top_proteins <- 30

# Set random seed for reproducibility
set.seed(101422)

# Step 1: Replace spaces in column names with underscores
colnames(training_data) <- make.names(colnames(training_data))

# Step 2: Ensure `group` is a factor (classification target)
training_data$group <- as.factor(training_data$group)

# Step 3: Exclude ADOS from the data
training_data <- training_data[, !names(training_data) %in% c("ados")]

# Step 4: Impute Missing Values in Transformed Training Data
preprocess <- preProcess(training_data, method = "medianImpute")
training_data_imputed <- predict(preprocess, training_data)

# Step 5: Feature Selection Methods

# Method 1: Random Forest
rf_model <- randomForest(group ~ ., data = training_data_imputed, importance = TRUE)
rf_importance <- importance(rf_model)
top_rf <- names(sort(rf_importance[, "MeanDecreaseAccuracy"], decreasing = TRUE))[1:num_top_proteins]
cat("Top proteins selected by Random Forest:\n", top_rf, "\n\n")

# Method 2: Lasso Regression
x <- as.matrix(training_data_imputed[, -1]) # Predictor matrix (excluding 'group')
y <- as.factor(training_data_imputed$group) # Response variable
lasso_model <- cv.glmnet(x, y, family = "binomial", alpha = 1) # Alpha = 1 for lasso
lasso_coef <- coef(lasso_model, s = "lambda.min")
top_lasso <- rownames(lasso_coef)[order(abs(lasso_coef[,1]), decreasing = TRUE)][2:(num_top_proteins+1)]
cat("Top proteins selected by Lasso Regression:\n", top_lasso, "\n\n")

# Method 3: t-test
# Run t-tests for each protein to identify proteins with the lowest p-values
t_test_pvalues <- sapply(training_data_imputed[, -1], function(protein) {
  t.test(protein ~ training_data_imputed$group)$p.value
})

# Select proteins with the smallest p-values
top_ttest <- names(sort(t_test_pvalues, decreasing = FALSE))[1:num_top_proteins]
cat("Top proteins selected by t-test:\n", top_ttest, "\n\n")

# Combine results from the three methods
list_of_protein_sets <- list(top_rf, top_lasso, top_ttest)

# Step 7: Fuzzy Intersection (select proteins appearing in at least 2 of the 3 methods)
fuzzy_intersection <- function(lists, threshold) {
  protein_counts <- table(unlist(lists))
  selected_proteins <- names(protein_counts[protein_counts >= threshold])
  return(selected_proteins)
}

# Select proteins that appear in at least 2 of the 3 methods
fuzzy_selected_proteins <- fuzzy_intersection(list_of_protein_sets, threshold = 2)
cat("Proteins selected by fuzzy intersection (appearing in at least 2 methods):\n", fuzzy_selected_proteins, "\n\n")

# Step 8: Summary and Analysis of Results
cat("Summary of Feature Selection Results:\n")
cat("Number of unique proteins selected by Random Forest:", length(top_rf), "\n")
cat("Number of unique proteins selected by Lasso Regression:", length(top_lasso), "\n")
cat("Number of unique proteins selected by t-test:", length(top_ttest), "\n")
cat("Number of proteins in fuzzy intersection (selected by at least 2 methods):", length(fuzzy_selected_proteins), "\n")
```
Implementing these modifications affected the results by enhancing model stability and potentially improving generalizability. Setting aside a test partition from the beginning and performing feature selection only on the training data provided an unbiased test accuracy assessment, which better reflects how the model might perform on unseen data. Expanding the number of top predictive proteins beyond ten for each method allowed the model to incorporate a broader range of potentially relevant features, which can capture more subtle patterns in the data. Finally, using a fuzzy intersection (selecting proteins that appear in at least two out of three methods) allowed for a balance between consistency and inclusivity, focusing on proteins with strong predictive signals across methods without being overly restrictive. Overall, these changes likely reduced overfitting and helped achieve a more robust model by ensuring feature selection and model evaluation were more representative of real-world conditions.

# Q4.
```{r}
# Load necessary libraries
library(glmnet)
library(pROC)

# Define the proteins selected by Lasso Regression
lasso_proteins_1 <- c("MAPK2", "X14.3.3.protein.zeta.delta", "FSTL1", "Protein.S", "FAM3D", 
                    "Epo", "Growth.hormone.receptor", "P.Cadherin", "Kallikrein.11", "PEDF", 
                    "PAI.1", "SIG14", "CXCL16..soluble", "ENTP5", "ENPP7", "CD27", "MIP.5", 
                    "NRP1", "HCE000104", "Calcineurin", "IGFBP.4", "PPID", "PYY", "SH21A", 
                    "FN1.3", "IDS", "Afamin", "CHIP")

# Prepare the training and test sets with only the selected proteins
train_data_lasso_1 <- train_data %>%
  select(all_of(c("group", lasso_proteins_1)))
test_data_lasso_1 <- test_data %>%
  select(all_of(c("group", lasso_proteins_1)))

# Convert the data into matrix format for glmnet
# `group` should be converted to numeric (binary) for binary classification
x_train_1 <- as.matrix(train_data_lasso_1[, -1])  # Exclude group column
y_train_1 <- as.numeric(as.factor(train_data_lasso_1$group)) - 1  # Convert group to binary (0 and 1)

# Train Lasso model using cross-validation to find the optimal lambda
lasso_model_1 <- cv.glmnet(x_train_1, y_train_1, family = "binomial", alpha = 1)

# Find the best lambda value
best_lambda_1 <- lasso_model_1$lambda.min
cat("Optimal lambda from cross-validation:", best_lambda_1, "\n")

# Convert the test data for predictions
x_test_1 <- as.matrix(test_data_lasso_1[, -1])  # Exclude group column
y_test_1 <- as.numeric(as.factor(test_data_lasso_1$group)) - 1  # Convert group to binary (0 and 1)

# Make predictions using the probability type for AUC calculation
lasso_preds_prob_1 <- predict(lasso_model_1, newx = x_test_1, s = best_lambda_1, type = "response")
lasso_preds_class_1 <- ifelse(lasso_preds_prob_1 > 0.5, 1, 0)  # Classify based on threshold of 0.5

# Calculate AUC
roc_curve_1 <- roc(y_test_1, as.numeric(lasso_preds_prob))
auc_value_1 <- auc(roc_curve_1)
cat("AUC of Lasso Regression model on test set:", auc_value, "\n")

# Calculate sensitivity and specificity
conf_matrix_1 <- table(Predicted = lasso_preds_class_1, Actual = y_test_1)
sensitivity_1 <- conf_matrix_1[2, 2] / (conf_matrix_1[2, 2] + conf_matrix_1[1, 2])  # TP / (TP + FN)
specificity_1 <- conf_matrix_1[1, 1] / (conf_matrix_1[1, 1] + conf_matrix_1[2, 1])  # TN / (TN + FP)

cat("Sensitivity of Lasso Regression model1 on test set:", sensitivity_1 * 100, "%\n")
cat("Specificity of Lasso Regression model1 on test set:", specificity_1 * 100, "%\n")
```

```{r}
# Define the proteins selected by Lasso Regression
lasso_proteins_2 <- c("MAPK2", "X14.3.3.protein.zeta.delta", "FSTL1", "Protein.S", "FAM3D", 
                    "Epo", "Growth.hormone.receptor", "P.Cadherin", "Kallikrein.11", "PEDF", 
                    "PAI.1", "SIG14", "CXCL16..soluble", "ENTP5", "ENPP7", "CD27", "MIP.5")

# Prepare the training and test sets with only the selected proteins
train_data_lasso_2 <- train_data %>%
  select(all_of(c("group", lasso_proteins_2)))
test_data_lasso_2 <- test_data %>%
  select(all_of(c("group", lasso_proteins_2)))

# Convert the data into matrix format for glmnet
# `group` should be converted to numeric (binary) for binary classification
x_train_2 <- as.matrix(train_data_lasso_2[, -1])  # Exclude group column
y_train_2 <- as.numeric(as.factor(train_data_lasso_2$group)) - 1  # Convert group to binary (0 and 1)

# Train Lasso model using cross-validation to find the optimal lambda
lasso_model_2 <- cv.glmnet(x_train_2, y_train_2, family = "binomial", alpha = 1)

# Find the best lambda value
best_lambda_2 <- lasso_model_2$lambda.min
cat("Optimal lambda from cross-validation:", best_lambda_2, "\n")

# Convert the test data for predictions
x_test_2 <- as.matrix(test_data_lasso_2[, -1])  # Exclude group column
y_test_2 <- as.numeric(as.factor(test_data_lasso_2$group)) - 1  # Convert group to binary (0 and 1)

# Make predictions using the probability type for AUC calculation
lasso_preds_prob_2 <- predict(lasso_model_2, newx = x_test_2, s = best_lambda_2, type = "response")
lasso_preds_class_2 <- ifelse(lasso_preds_prob_2 > 0.5, 1, 0)  # Classify based on threshold of 0.5

# Calculate AUC
roc_curve_2 <- roc(y_test_2, as.numeric(lasso_preds_prob_2))
auc_value_2 <- auc(roc_curve_2)
cat("AUC of Lasso Regression model on test set:", auc_value_2, "\n")

# Calculate sensitivity and specificity
conf_matrix_2 <- table(Predicted = lasso_preds_class_2, Actual = y_test_2)
sensitivity_2 <- conf_matrix_2[2, 2] / (conf_matrix_2[2, 2] + conf_matrix_2[1, 2])  # TP / (TP + FN)
specificity_2 <- conf_matrix_2[1, 1] / (conf_matrix_2[1, 1] + conf_matrix_2[2, 1])  # TN / (TN + FP)

cat("Sensitivity of Lasso Regression model2 on test set:", sensitivity_2 * 100, "%\n")
cat("Specificity of Lasso Regression model2 on test set:", specificity_2 * 100, "%\n")
```

The results from the two Lasso models suggest that Model 1 with a lambda of 0.0264 outperformed Model 2 (lambda 0.0166) in both AUC and classification accuracy. Model 1 achieved an AUC of 0.92 with balanced sensitivity and specificity of 83.3%, while Model 2 showed a lower AUC of 0.85, with lower sensitivity (75%) and specificity (66.7%). These findings indicate that the feature set for Model 1 is more predictive and generalizes better than Model 2’s feature set.

Benchmarking these models against the in-class analysis shows that Model 1’s balanced performance and high AUC demonstrate a strong predictive model that could serve as a robust classifier, given its ability to maintain high accuracy and generalizability across different sets of proteins. The exploration of simpler or alternative panels might yield a refined model with fewer but highly impactful proteins, aiming for a similar classification performance.








